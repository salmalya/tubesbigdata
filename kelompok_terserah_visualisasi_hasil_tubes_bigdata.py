# -*- coding: utf-8 -*-
"""Kelompok Terserah - Visualisasi Hasil Tubes BigData.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1yIYyRtfRyDnDWqZqCDkvRccBtFPAsbv-
"""

# Install necessary libraries
!pip install azure-storage-blob
!pip install pyspark
!pip install -U seaborn

# Import necessary libraries
from azure.storage.blob import BlobServiceClient
import pandas as pd
import matplotlib.pyplot as plt
from pyspark.sql import SparkSession
from pyspark.sql.functions import col
from pyspark.ml.stat import Correlation
from pyspark.ml.feature import VectorAssembler
import seaborn as sns
from io import StringIO

# Azure Storage details
STORAGE_ACCOUNT_NAME = "crawlingdataa"
STORAGE_ACCOUNT_KEY = "moAXebyYOB7h7frZn66QM6sX1aQHDOwRKWJ7WYcYihzOcbVbkuSghL/gEddqcVAmE5AbEjWB4vcS+AStRE0whg=="
CONTAINER_NAME = "scraped-data"
BLOB_NAME = "transformed_datav2.csv/part-00000-tid-7765410215177894825-917cf624-9495-4b4a-a294-00d1ea429521-89-1-c000.csv"

# Connect to Azure Blob Storage
blob_service_client = BlobServiceClient(
    account_url=f"https://{STORAGE_ACCOUNT_NAME}.blob.core.windows.net/",
    credential=STORAGE_ACCOUNT_KEY
)
blob_client = blob_service_client.get_blob_client(container=CONTAINER_NAME, blob=BLOB_NAME)

# Download the CSV file
downloaded_blob = blob_client.download_blob()
data = downloaded_blob.content_as_text()

# Load data into a Pandas DataFrame
df = pd.read_csv(StringIO(data))

# Preprocess Data
df['Tanggal'] = pd.to_datetime(df['Tanggal'])
df['Open'].fillna(df['Open'].mean(), inplace=True)
df['Low'].fillna(df['Low'].mean(), inplace=True)
df['High'].fillna(df['High'].mean(), inplace=True)
df['Close'].fillna(df['Close'].mean(), inplace=True)
df['Volume'].fillna(df['Volume'].mean(), inplace=True)

# Sort data by date
df = df.sort_values(by='Tanggal')

# Display basic information
print(df.head())
print(df.info())

# Plot the gold price trend
plt.figure(figsize=(10, 6))
plt.plot(df['Tanggal'], df['GOLD'], label='Harga Emas', color='gold')
plt.title('Tren Harga Emas Berdasarkan Tanggal')
plt.xlabel('Tanggal')
plt.ylabel('Harga Emas (Rp)')
plt.xticks(rotation=45)
plt.legend()
plt.grid()
plt.show()

# Plot the silver price trend
plt.figure(figsize=(10, 6))
plt.plot(df['Tanggal'], df['SILVER'], label='Harga Perak', color='silver')
plt.title('Tren Harga Perak Berdasarkan Tanggal')
plt.xlabel('Tanggal')
plt.ylabel('Harga Perak (Rp)')
plt.xticks(rotation=45)
plt.legend()
plt.grid()
plt.show()

# Plot the stock volume trend
plt.figure(figsize=(10, 6))
plt.plot(df['Tanggal'], df['Volume'], label='Volume Saham', color='blue')
plt.title('Tren Volume Saham Berdasarkan Tanggal')
plt.xlabel('Tanggal')
plt.ylabel('Volume Saham')
plt.xticks(rotation=45)
plt.legend()
plt.grid()
plt.show()

# Initialize PySpark session
spark = SparkSession.builder \
    .appName("CorrelationAnalysis") \
    .config("spark.ui.port", "4050") \
    .getOrCreate()

# Convert Pandas DataFrame to PySpark DataFrame
spark_df = spark.createDataFrame(df)

# Prepare data for correlation analysis
assembler = VectorAssembler(inputCols=["GOLD", "SILVER", "Open", "High", "Low", "Close", "Volume"], outputCol="features")
assembled_df = assembler.transform(spark_df)

# Compute correlation matrix
correlation_matrix = Correlation.corr(assembled_df, "features").head()[0].toArray()

# Display the correlation matrix
print("Matriks Korelasi:")
print(correlation_matrix)

# Convert the correlation matrix into a Pandas DataFrame for better visualization
correlation_df = pd.DataFrame(
    correlation_matrix,
    index=["GOLD", "SILVER", "Open", "High", "Low", "Close", "Volume"],
    columns=["GOLD", "SILVER", "Open", "High", "Low", "Close", "Volume"]
)

# Plot the correlation matrix
plt.figure(figsize=(8, 6))
sns.heatmap(correlation_df, annot=True, cmap='coolwarm', fmt=".2f", linewidths=0.5)
plt.title('Matriks Korelasi')
plt.show()